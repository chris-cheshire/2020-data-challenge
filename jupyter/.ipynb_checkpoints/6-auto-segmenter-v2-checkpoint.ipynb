{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import img_as_ubyte\n",
    "from skimage import exposure\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_bound(image, angle):\n",
    "    # grab the dimensions of the image and then determine the\n",
    "    # center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    # grab the rotation matrix (applying the negative of the\n",
    "    # angle to rotate clockwise), then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "    # perform the actual rotation and return the image\n",
    "    return cv2.warpAffine(image, M, (nW, nH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = '../data'\n",
    "frames_path = '../data/tif'\n",
    "output_path = '../data/auto_seg_tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 1100\n",
    "\n",
    "angle_increment = 2\n",
    "min_angle = 10\n",
    "max_angle = 80\n",
    "\n",
    "blur_amount = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABfCAYAAADWOh2AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAACgUlEQVR4nO3dQW7TQBiAURtxBdYcItz/Bhyi+97BLBGpQR5S57Pj96Rsoqp2o+jTKH9mOi/LMgHwfF/qGwC4KgEGiAgwQESAASICDBARYIDI15EfnufZd9YAxr0vy/Lt/kkrYID9va09KcAAEQEGiAx9BrzVo9ub53n+pDsBOC4rYICIAANEBBggIsAAkYeHcHucJ7z1dxrWAWdmBQwQEWCAiAADRAQYICLAAJGhAN9ut2lZlj8epft7OeJj5L6Ba7ECBogIMEBEgAEiAgwQ2eU8YH4bGa49YxD3t+3brz4EHNm2ftbXYo+t+Wuvxdp1Pvs1u8oxA1bAABEBBogIMEBEgAEi88iH5/M8b/rhsw4xgPPZOhSMB3s/l2X5cf+kFTBARIABIgIMEBFggMguO+GusOsIOIatDXm0NXsM8ayAASICDBARYICIAANE8uMot36wbVgHlLY2aGRYZwUMEBFggIgAA0QEGCAiwACR/FsQWz3jHwECPGrkLGIrYICIAANEBBggIsAAkdMM4dYYzP3bs85ljv/Z4QfeA5yFFTBARIABIgIMEBFggMiph3BndbSh1TQd857+19H+lpGdUWe9zppHrn2VQaoVMEBEgAEiAgwQEWCAiCHcBkcb6nAuz3r/vNJ1nrWLs2YFDBARYICIAANEBBgg8nJDOAMzuJYzH0trBQwQEWCAiAADRAQYICLAAJGX+xYEwFm+GWEFDBARYICIAANEBBggYggHXMLWYwoeHdaNHIdgBQwQEWCAiAADRAQYIDI6hHufpultjxsBOIKdzhT/vnqtI27PA7gCH0EARAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRH4BzgUGvemykTkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_mask = cv2.imread(os.path.join(mask_path,'mask-1-cropped.jpg'),0)\n",
    "ret, img_mask = cv2.threshold(img_mask, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure()\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.imshow(img_mask,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = \"s_12_z_1\"\n",
    "tiff_path = os.path.join(frames_path, \"fid - DCE_FLASH_1.28ms (E9) _s_12_z_1.tif\")\n",
    "tiff_image = io.MultiImage(tiff_path)\n",
    "\n",
    "# gamma_corrected = exposure.adjust_gamma(tiff_image[0], 2)\n",
    "# img = img_as_ubyte(gamma_corrected)\n",
    "#norm_img = np.zeros(img.shape)\n",
    "#final_img = cv2.normalize(img, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "#print(img)\n",
    "#print(norm_img)\n",
    "\n",
    "# print(img)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.xticks([]),plt.yticks([])\n",
    "# plt.imshow(img,'gray')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.xticks([]),plt.yticks([])\n",
    "# plt.imshow(norm_img,'gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mask(frame_no):\n",
    "    # Get file name\n",
    "    file_name = \"frame-%d.jpg\" % frame_no\n",
    "    \n",
    "    # Open image and pre-process\n",
    "    #img_orig = cv2.imread(os.path.join(frames_path,file_name),0)\n",
    "    gamma_corrected = exposure.adjust_gamma(tiff_image[0], 2)\n",
    "    img_orig = img_as_ubyte(gamma_corrected)\n",
    "    #img_temp = np.zeros(img_orig.shape)\n",
    "    #img_norm = cv2.normalize(img_orig, img_temp, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    img_blur = cv2.medianBlur(img_orig, blur_amount)\n",
    "    img_thresh = cv2.adaptiveThreshold(img_blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    img_thresh_inv = cv2.bitwise_not(img_thresh)\n",
    "    \n",
    "    # Init variables\n",
    "    angle = min_angle\n",
    "    images = []\n",
    "    scores = []\n",
    "    positions = []\n",
    "    rows,cols = img_orig.shape\n",
    "    \n",
    "    # Log\n",
    "    #print(\"Frame {0} has {1} rows and {2} cols\".format(i,rows,cols))\n",
    "    \n",
    "    while angle <= max_angle:\n",
    "    \n",
    "        # Rotate mask and log\n",
    "        img_mask_rotated = rotate_bound(img_mask, angle)\n",
    "        ret, img_mask_rotated = cv2.threshold(img_mask_rotated, 1, 255, cv2.THRESH_BINARY)\n",
    "        mask_rows,mask_cols = img_mask_rotated.shape\n",
    "        #print(\"Current rotation {2} degrees has {0} rows and {1} cols\".format(mask_rows,mask_cols,angle))\n",
    "    \n",
    "        # Pass image over\n",
    "        for i in range(rows):\n",
    "            if i + mask_rows > rows:\n",
    "                continue\n",
    "            for j in range(cols):\n",
    "                if j + mask_cols > cols:\n",
    "                    continue\n",
    "            \n",
    "                # Create roi\n",
    "                roi = img_thresh_inv[i:mask_rows+i,j:mask_cols+j]\n",
    "\n",
    "                # Mask with mask\n",
    "                masked = cv2.bitwise_and(roi,img_mask_rotated)\n",
    "            \n",
    "                # Save image and scores\n",
    "                images.append(masked)\n",
    "                scores.append(masked.sum())\n",
    "                positions.append([i,j,angle])\n",
    "            \n",
    "        angle += angle_increment\n",
    "    \n",
    "    max_score = np.max(scores)\n",
    "    max_index = np.argmax(scores)\n",
    "    best_position = positions[max_index]\n",
    "    \n",
    "    # Reload the best mask\n",
    "    img_mask_rotated = rotate_bound(img_mask, best_position[2])\n",
    "    ret, img_mask_rotated = cv2.threshold(img_mask_rotated, 1, 255, cv2.THRESH_BINARY)\n",
    "    mask_rows,mask_cols = img_mask_rotated.shape\n",
    "    \n",
    "    # Output mask in a full sized image\n",
    "    final_mask = np.zeros(img_orig.shape)\n",
    "    final_mask[best_position[0]:mask_rows+best_position[0],best_position[1]:mask_cols+best_position[1]] = img_mask_rotated\n",
    "    \n",
    "    # Create final roi based on cropped mask\n",
    "    roi1 = img_orig[best_position[0]:mask_rows+best_position[0],best_position[1]:mask_cols+best_position[1]]\n",
    "    masked_orig = cv2.bitwise_and(roi1,img_mask_rotated)\n",
    "    \n",
    "    # Normalise final crop ignoring zeroes\n",
    "    minval = np.min(masked_orig[np.nonzero(masked_orig)])\n",
    "    maxval = np.max(masked_orig[np.nonzero(masked_orig)])\n",
    "    masked_norm = (masked_norm - minval) / (maxval - minval)\n",
    "    \n",
    "    minval = np.min(masked_norm)\n",
    "    maxval = np.max(masked_norm)   \n",
    "    print(minval)\n",
    "    print(maxval)\n",
    "    \n",
    "    # Create large image with cropped real image in it\n",
    "    final_mask_orig = np.zeros(img_orig.shape)\n",
    "    final_mask_orig[best_position[0]:mask_rows+best_position[0],best_position[1]:mask_cols+best_position[1]] = masked_orig\n",
    "    \n",
    "    # Save mask and frame to file\n",
    "    frame_name = \"frame-%d.png\" % frame_no\n",
    "    mask_name = \"mask-%d.png\" % frame_no\n",
    "    crop_name = \"crop-%d.png\" % frame_no\n",
    "    real_name = \"real-%d.png\" % frame_no\n",
    "    \n",
    "    cv2.imwrite(os.path.join(output_path,sample_id,\"frames\",frame_name), img_orig)\n",
    "    cv2.imwrite(os.path.join(output_path,sample_id,\"masks\",mask_name), final_mask)\n",
    "    cv2.imwrite(os.path.join(output_path,sample_id,\"crops\",crop_name), masked_norm) \n",
    "    cv2.imwrite(os.path.join(output_path,sample_id,\"real_masks\",real_name), final_mask_orig)\n",
    "    \n",
    "    #print(\"Frame {0}: MS={1} BP-X:{2} BP-Y:{3} BP-A:{4}\".format(frame_no,max_score,best_position[0],best_position[1],best_position[2]))    \n",
    "    return [frame_no,max_score,best_position[0],best_position[1],best_position[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "161\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'masked_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-49bf16c722ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe_no\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Frame {0}: MS={1} BP-X:{2} BP-Y:{3} BP-A:{4}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c8f1637d0e7e>\u001b[0m in \u001b[0;36mfind_mask\u001b[0;34m(frame_no)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Create large image with cropped real image in it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mfinal_mask_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mfinal_mask_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_position\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmask_rows\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbest_position\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_position\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmask_cols\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbest_position\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Save mask and frame to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'masked_norm' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for frame_no in range(frame_count):\n",
    "    result = find_mask(frame_no)\n",
    "    print(\"Frame {0}: MS={1} BP-X:{2} BP-Y:{3} BP-A:{4}\".format(result[0],result[1],result[2],result[3],result[4]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run mult-threaded\n",
    "# results = []\n",
    "# frame_range = range(frame_count)\n",
    "# with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#     futures = [executor.submit(find_mask, frame_no) for frame_no in frame_range]\n",
    "    \n",
    "#     for future in concurrent.futures.as_completed(futures):\n",
    "#         result = future.result()\n",
    "#         results.append(result)\n",
    "#         print(\"Frame {0}: MS={1} BP-X:{2} BP-Y:{3} BP-A:{4}\".format(result[0],result[1],result[2],result[3],result[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results)\n",
    "np.savetxt(os.path.join(output_path,sample_id,\"summary.csv\"),results, header=\"frame_no,score,xpos,ypos,angle\",delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
